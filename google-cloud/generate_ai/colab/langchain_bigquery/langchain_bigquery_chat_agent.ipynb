{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bwnyasse/learning-box/blob/main/google-cloud/generate_ai/colab/langchain_bigquery/langchain_bigquery_chat_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShUJUEKt9hlC"
      },
      "outputs": [],
      "source": [
        "# My Learning Box - Google Cloud - Colab\n",
        "# Copyright 2023 Boris-Wilfried\n",
        "#\n",
        "# This Google Colab notebook is part of my \"Learning Box\" github repository, created for my learning purposes.\n",
        "# It is not designed for production use.\n",
        "# This notebook may serve as an inspiration or a starting point for your own explorations.\n",
        "# For any queries, suggestions, or contributions, feel free to reach out to me on GitHub: https://github.com/bwnyasse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bwnyasse/learning-box/blob/main/google-cloud/colab/langchain_bigquery/langchain_bigquery_chat_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmC5pcouOMao"
      },
      "source": [
        "# **Using LangChain and GPT to chat with BigQuery data**\n",
        "\n",
        "---\n",
        "\n",
        "In this Colab, I want to demonstrate how to use LangChain and OpenAI GPT for querying data from Google BigQuery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoRDXVtJ8DLb"
      },
      "source": [
        "## üìí Before I begin.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ywkn4-oPaZy"
      },
      "source": [
        "#### Setup Google Cloud Project.\n",
        "\n",
        "1.   Create a Cloud Platform project if you do not already have one.\n",
        "2.   Enable billing for the project.\n",
        "3.   Enable BigQuery APIs for the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICZc-6sNPhDR"
      },
      "source": [
        "### Authentication and service account.\n",
        "\n",
        "1. Create a service account if you do not already have one, with the following Bigquery Roles:\n",
        "\n",
        "  *  BigQuery User\n",
        "  *  BigQuery Data Viewer\n",
        "  *  BigQuery Job User\n",
        "\n",
        "\n",
        "2. Download the service account key json and put it `/content/sa-keys/sa-langchain-test-over-bigquery.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOdHYd3sNKOL"
      },
      "source": [
        "## üêç Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_4f3dptQGSX"
      },
      "source": [
        "### Installation of required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ivKWo3td8DvW"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform langchain openai chromadb tiktoken tabulate sqlalchemy sqlalchemy-bigquery google-cloud-bigquery &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwMZS21K8gGe"
      },
      "source": [
        "### Importing libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h1ET8RCA9A3_"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google.cloud import bigquery\n",
        "from sqlalchemy import *\n",
        "from sqlalchemy.engine import create_engine\n",
        "from sqlalchemy.schema import *\n",
        "import os\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.agents import AgentExecutor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N75wW1dT8j0c"
      },
      "source": [
        "## üîê Authenticate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAeuvsWqQjQj"
      },
      "source": [
        "### BigQuery Service Account : Option 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qFyA9jA91Y-",
        "outputId": "f4e17f8d-52a7-4b70-bc52-7c73f878d7bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Option 1: For Personal Use (with Google Drive)\n",
        "# Uncomment the following lines if you have stored your service account key in Google Drive.\n",
        "# This is how I, the author, personally use it for demonstration purposes.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "service_account_file = \"/content/gdrive/MyDrive/Colab Notebooks/sa-keys/sa-langchain-test-over-bigquery.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lz7oX-B9hlH"
      },
      "source": [
        "### BigQuery Service Account : Option 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lcMuRpm9hlH"
      },
      "outputs": [],
      "source": [
        "# Option 2: General User Setup\n",
        "# Uncomment and use the following line if you have placed your service account key in the /content directory of this Colab notebook.\n",
        "# This is the recommended way for general users who are following the instructions from the documentation.\n",
        "# service_account_file = \"/content/sa-keys/sa-langchain-test-over-bigquery.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39qgCc2o-Sqx"
      },
      "source": [
        "## üß† LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3sXkKGh-Z8J"
      },
      "source": [
        "### Vertex AI\n",
        "\n",
        "\n",
        "Before we proceed with the utilization of Vertex AI services, it's necessary to initialize the Vertex AI environment. This is crucial for setting up the project context and specifying the region where the AI services will be accessed.\n",
        "\n",
        "Make sure you have the necessary permissions and that the Vertex AI API is enabled in your Google Cloud project.\n",
        "\n",
        "**Note**: Replace the `PROJECT_ID` with your own Google Cloud project ID if different.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JfWPGnFN-kza"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = \"learning-box-369917\"\n",
        "vertexai.init(project=PROJECT_ID, location=\"northamerica-northeast1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toYpccLj-1UN"
      },
      "source": [
        "### OpenAI API\n",
        "\n",
        "In order to interact with OpenAI's GPT models, you need to have an OpenAI API key. Here's how you can set it up:\n",
        "\n",
        "1. **Generate an OpenAI API Key**: If you don't have one, you need to create an API key from your OpenAI account. Visit the OpenAI website, log in to your account, and navigate to the API section to generate a new key.\n",
        "\n",
        "2. **Storing the OpenAI API Key**: For the purpose of this Colab notebook, store your OpenAI API key in a secure location. If you are using Google Colab's secret section for sensitive data, you can add your key there. Alternatively, you can store it in an environment variable or a secure file within the Colab file system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q7u5Qvb8-t0B"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Use the following line to access your secret key (replace 'your_secret_key_name' with the actual name of your key)\n",
        "# openai_key = 'your_secret_key'  # Replace with the name of your key in the secret section\n",
        "openai_key = userdata.get('openAiApiKey')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVH_S5xm_BtL"
      },
      "source": [
        "### Validate version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijaku3LA_E1s",
        "outputId": "c0576f3a-d682-4224-dd75-d99d5a85be6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain version: 0.0.346\n",
            "Vertex AI SDK version: 1.36.4\n"
          ]
        }
      ],
      "source": [
        "import google.cloud.bigquery as bq\n",
        "import langchain\n",
        "from google.cloud import aiplatform\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.document_loaders import BigQueryLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import format_document\n",
        "\n",
        "# Print LangChain and Vertex AI versions\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6k0ahR7-nfQ"
      },
      "source": [
        "## üíª SQL Achemy Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xfzyWtjV-rmk"
      },
      "outputs": [],
      "source": [
        "#@markdown Which dataset do I want to use ?\n",
        "\n",
        "# Configuration\n",
        "PROJECT_ID = \"learning-box-369917\"\n",
        "dataset = \"langchain_test_churn_table\" #@param {type:\"string\"}\n",
        "sqlalchemy_url = f'bigquery://{PROJECT_ID}/{dataset}?credentials_path={service_account_file}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbNvTCLxHdHq"
      },
      "source": [
        "## üîó Initialize LangChain\n",
        "\n",
        "Set up the LangChain with the specified configurations to prepare for executing queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4KwaC_3wHeaA"
      },
      "outputs": [],
      "source": [
        "# Assume option is obtained from the dropdown\n",
        "option = 'vertex_ai'  # @param [\"open_ai\", \"vertex_ai\"]\n",
        "\n",
        "# Initialize llm based on the selected option\n",
        "if option == 'open_ai':\n",
        "    llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
        "elif option == 'vertex_ai':\n",
        "    llm = VertexAI(model_name=\"text-bison@001\", temperature=0)\n",
        "else:\n",
        "    raise ValueError(\"Invalid option selected\")\n",
        "\n",
        "\n",
        "db = SQLDatabase.from_uri(sqlalchemy_url)\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    top_k=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke6_go_JH5BL"
      },
      "source": [
        "## üí¨ Chat : Execute and Display Queries\n",
        "\n",
        "Execute sample queries using the LangChain agent and display the responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoDsy1ZU9hlH"
      },
      "source": [
        "### Utility to parse output into json format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "03GSHxYS9hlI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def remove_ansi_escape_codes(text):\n",
        "    # ANSI escape code regex\n",
        "    ansi_escape = re.compile(r'\\x1B[@-_][0-?]*[ -/]*[@-~]')\n",
        "    return ansi_escape.sub('', text)\n",
        "\n",
        "def parse_response_to_json(text):\n",
        "    # Initialize the structure\n",
        "    response_json = {\n",
        "        \"ai\": [],\n",
        "        \"final_answer\": \"\"\n",
        "    }\n",
        "\n",
        "    current_ai_entry = {\"thought\": \"\", \"action\": \"\", \"action_input\": \"\"}\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        cleaned_line = remove_ansi_escape_codes(line)\n",
        "\n",
        "        thought_match = re.match(r'^Thought: (.+)', cleaned_line)\n",
        "        action_match = re.match(r'^Action: (.+)', cleaned_line)\n",
        "        action_input_match = re.match(r'^Action Input: (.+)', cleaned_line)\n",
        "        final_answer_match = re.match(r'^Final Answer: (.+)', cleaned_line)\n",
        "\n",
        "        if thought_match:\n",
        "            if current_ai_entry[\"thought\"]:  # If there's already a thought in the current entry, append it and start a new one\n",
        "                response_json[\"ai\"].append(current_ai_entry)\n",
        "                current_ai_entry = {\"thought\": \"\", \"action\": \"\", \"action_input\": \"\"}\n",
        "\n",
        "            current_ai_entry[\"thought\"] = thought_match.group(1)\n",
        "\n",
        "        if action_match:\n",
        "            current_ai_entry[\"action\"] = action_match.group(1)\n",
        "\n",
        "        if action_input_match:\n",
        "            current_ai_entry[\"action_input\"] = action_input_match.group(1)\n",
        "\n",
        "        if final_answer_match:\n",
        "            response_json[\"final_answer\"] = final_answer_match.group(1)\n",
        "\n",
        "    # Append the last AI entry if it's not empty\n",
        "    if current_ai_entry[\"thought\"] or current_ai_entry[\"action\"] or current_ai_entry[\"action_input\"]:\n",
        "        response_json[\"ai\"].append(current_ai_entry)\n",
        "\n",
        "    return json.dumps(response_json, indent=2)\n",
        "\n",
        "import sys\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "def capture_console_output(func, *args, **kwargs):\n",
        "    f = io.StringIO()\n",
        "    with redirect_stdout(f):\n",
        "        func(*args, **kwargs)\n",
        "    return f.getvalue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz_UBDbO9hlI"
      },
      "source": [
        "### Interacting with **Churn Table** ( Sample questions )\n",
        "\n",
        "\n",
        "1. **Customer Demographics:**\n",
        "\n",
        "\"What is the distribution of churned customers by gender and age group (SeniorCitizen)?\"\n",
        "\n",
        "2. **Service Usage Patterns:**\n",
        "\n",
        "\"Which internet service types have the highest churn rates among customers?\"\n",
        "\n",
        "3. **Customer Loyalty and Tenure:**\n",
        "\n",
        "\"What is the average tenure of customers who churn compared to those who stay?\"\n",
        "\n",
        "4. **Churn Analysis:**\n",
        "\n",
        "\"What are the common characteristics of customers who churn within their first year?\"\n",
        "\n",
        "5. **Billing and Payment Trends:**\n",
        "\n",
        "\"How does the average monthly charge differ between customers who churn and those who don‚Äôt?\"\n",
        "\n",
        "6. **Contract Preferences:**\n",
        "\n",
        "\"What percentage of customers on a month-to-month contract churn compared to those on one-year or two-year contracts?\"\n",
        "\n",
        "7. **Customer Satisfaction Indicators:**\n",
        "\n",
        "\"Is there a correlation between the use of tech support services and customer churn rates?\"\n",
        "\n",
        "8. **Segmentation and Personalized Marketing:**\n",
        "\n",
        "\"Can we identify distinct customer segments based on service usage patterns and churn rates?\"\n",
        "\n",
        "9. **Predictive Analysis:**\n",
        "\n",
        "\"Which factors are most predictive of churn in our customer base?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01uBBaIy9hlI"
      },
      "source": [
        "### Interacting with **Amazon Canada Products 2023** ( Sample questions )\n",
        "\n",
        "I have pulled the data from a public dataset available in [kaddle](https://www.kaggle.com/datasets/asaniczka/amazon-canada-products-2023-2-1m-products)\n",
        "\n",
        "1. **Product Popularity and Performance:**\n",
        "\n",
        "\"Which products (identified by asin) have the highest number of reviews (reviews) and what are their average star ratings (stars)?\"\n",
        "\n",
        "2. **Best Sellers and Categories Analysis:**\n",
        "\n",
        "\"In which categories (categoryName) do the most bestseller products (isBestSeller = True) fall, and what is their average price (price)?\"\n",
        "\n",
        "3. **Pricing Strategy Insights:**\n",
        "\n",
        "\"For products with a high star rating (stars > 4.0), how does their selling price (price) compare to the list price (listPrice)?\"\n",
        "\n",
        "4. **Recent Purchase Trends:**\n",
        "\n",
        "\"What are the top five products that have been bought most frequently in the last month (boughtInLastMonth), and what are their categories (categoryName)?\"\n",
        "\n",
        "5. **Correlation Between Price and Popularity:**\n",
        "\n",
        "\"Is there a correlation between the price (price) of a product and its popularity in terms of reviews (reviews) or being a bestseller (isBestSeller)?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j81KAq15H6TF"
      },
      "outputs": [],
      "source": [
        "#@markdown Please fill in the value below with your request.\n",
        "\n",
        "# Please fill in these values.\n",
        "request = \"What is the distribution of churned customers by gender and age group (SeniorCitizen)?\" #@param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert request, \"‚ö†Ô∏è Please provide a request\"\n",
        "\n",
        "response_text = capture_console_output(agent_executor.run, {request})\n",
        "json_output = parse_response_to_json(response_text)\n",
        "\n",
        "print(response_text)\n",
        "\n",
        "print(json_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E_4f3dptQGSX"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
